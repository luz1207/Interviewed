# 1. 卷积有什么特点
```text
1. 局部感受野：卷积通过一个较小的滤波器来滑动滤遍输入，滤波器只能关注局部特征
每一次的卷积操作只能处理局部的特征。
2. 权值共享：在卷积操作中使用的都是同一个卷积核，这大大的减少了参数量
3. 平移不变性：卷积操作具有一定的平移不变性。也就是说，卷积网络能够识别图像中的某些特征，无论这些特征的位置如何变化。
卷积核提取到的特征能够在不同的空间位置上进行识别和表达。
```
# 2. 有什么归一化方法
|   归一化方法   |              原理               |                                                           优点                                                           |
|:---------:|:-----------------------------:|:----------------------------------------------------------------------------------------------------------------------:|
|   批归一化    | 通过对每一层的输出在一个小批量（batch）内进行标准化，BN应作用在非线性映射前 |                                              1. 加快模型训练速度<br/>2. 缓解梯度爆炸的问题                                              |
|   层归一化    |  神经网络的每一层中，对该层所有神经元的激活值进行归一化  | 1. 防止了激活值过大或过小导致的梯度消失或梯度爆炸问题<br/>2. 相比 Batch Normalization，LayerNorm 更适用于小批量训练、序列建模（如 RNN）等场景，因为它不依赖于 mini-batch 的统计信息 |
|实例归一化|每个样本在通道维度上进行归一化，通常用于风格迁移和图像生成任务|                                                可以有效控制图像的风格和内容分离，增强生成效果                                                 |

# 3. 在分类任务中，如果你需要输出七种类别，但实际上你输出的结果多了一个维度，请问你该如何用pytorch来解决
* 去除多余的维度，可以通过裁剪输出的最后一列（或指定维度）来解决问题
* 使用切片：截取前七个输出与目标匹配并输入到损失函数中
* 使用自定义的标签映射：如果第 8 类实际上需要映射为某种特殊状态（比如 "其他" 或 "背景"），可以在损失函数处理之前，自定义对输出的逻辑调整。